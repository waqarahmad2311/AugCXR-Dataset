{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65698be-5276-4560-b193-11f882411813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bf1b5-69fb-4cfd-9a77-e16e26395684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seeds for the reproducibility of the results\n",
    "# The segments of the code were taken from\n",
    "# https://keras.io/api/utils/python_utils/#set_random_seed-function\n",
    "# https://github.com/keras-team/keras/\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef285e3-57e3-4fb0-a9f8-69a9b3dee9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "img_size = (128, 128)\n",
    "batch_size = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255) # normalizing images to the range [0, 1] by dividing pixel values by 255.\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validate_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Generating batches of images and labels from the specified directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/aug2/train',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validate_datagen.flow_from_directory(\n",
    "    'dataset/aug2/val',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/aug2/test',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False # For test data, with shuffle=False, is used to ensure predictions align with true labels for evaluation.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac2ec6-0eac-4501-981e-1bebad8ad331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 Model\n",
    "\n",
    "# Model Building\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) # Reduces the dimensions of the feature maps to a single vector by averaging over spatial dimensions (width and height or feature map of image)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False # Freezes the layers of MobileNetV2 to prevent them from being updated during training and will only train the new added top layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd499911-287e-409f-9f19-a085b4ce9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590afe94-30df-4a10-9299-42d6faf825f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0f1c8-c343-4310-8f92-7e6f43b45f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('mobilenetv2_best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=60,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ece94-de73-47b1-aae1-8d2f0bb53879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "model.load_weights('mobilenetv2_best_model.keras')\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62eddc-5d5a-4784-a08a-5695298b2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision, Recall, and F1-Score\n",
    "test_generator.reset() # to ensure that the generator starts from the beginning of the dataset and produces predictions for the entire test set correctly\n",
    "Y_pred = model.predict(test_generator) # Predicts labels for the test data.\n",
    "y_pred = (Y_pred > 0.5).astype(int) # Converts predicted probabilities to binary labels (converting to integer array)\n",
    "y_true = test_generator.classes # providing the true labels for the images in the test set\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a2db1-3228-4db4-be92-1b108ead145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training & Validation Accuracy\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
    "plt.xlim(-.1, 60)\n",
    "plt.ylim(0.82, 1.01)\n",
    "plt.savefig('model_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2c321-f019-4b70-894c-0ef636302e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training & Validation Loss\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.xlim(0, 60)\n",
    "plt.ylim(-0.09, 0.8)\n",
    "plt.savefig('model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925c4cf-235c-49e9-8a92-cb7fe4dd4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e572d-0db8-4c66-9c92-7d53bacba2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC Curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, Y_pred)\n",
    "auc_score = roc_auc_score(y_true, Y_pred)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf866657-cca0-4c5c-821d-a6851a9cd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.savefig('roc_auc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed3f4b-4de0-4b9f-a49a-32e0aa7e9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_true_model3.npy', y_true)\n",
    "np.save('y_pred_proba_model3.npy', y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
