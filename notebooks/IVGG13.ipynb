{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65698be-5276-4560-b193-11f882411813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import os #imported for file management purposes like loading the dataset etc\n",
    "import random # for generating random numbers\n",
    "import numpy as np # for numerical computations\n",
    "import tensorflow as tf # for performing deep learning operations\n",
    "from keras.preprocessing import image #  imported Keras for building and training the CNN models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\n",
    "import matplotlib.pyplot as plt # imported for plotting the training/validation accuracy plots\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3f277-331a-4708-9a0f-162ebb0b8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seeds for the reproducibility of the results\n",
    "# The segments of the code were taken from\n",
    "# https://keras.io/api/utils/python_utils/#set_random_seed-function\n",
    "# https://github.com/keras-team/keras/blob/f6c4ac55692c132cd16211f4877fac6dbeead749/keras/src/applications/vgg16.py#L20-L226\n",
    "\n",
    "tf.random.set_seed(5)\n",
    "np.random.seed(5)\n",
    "random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef285e3-57e3-4fb0-a9f8-69a9b3dee9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining IVGG13 Model Architecture\n",
    "# The main code was taken from https://github.com/keras-team/keras/blob/f6c4ac55692c132cd16211f4877fac6dbeead749/keras/src/applications/vgg16.py#L20-L226\n",
    "# and inspiration of making modifications in the code were taken from https://pysource.com/2022/10/04/vgg16-from-scratch-computer-vision-with-keras-p-7/\n",
    "\n",
    "def IVGG13(input_shape, num_classes):\n",
    "\n",
    "     # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    # Classification block\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "    outputs = Dense(num_classes, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "    # Creating model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac2ec6-0eac-4501-981e-1bebad8ad331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input image shape\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Number of classes in our dataset i.e. Normal or Pneumonia\n",
    "num_classes = 1 # This line indicates that the output layer should have 1 neuron (since it is a binary classification).\n",
    "\n",
    "model = IVGG13(input_shape=input_shape, num_classes=num_classes)\n",
    "# building the neural network using the specified design provided by the function.\n",
    "# Once created, this model is further used in the training and evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd499911-287e-409f-9f19-a085b4ce9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model and setting up the hyperparameters (same as mentioned in the research paper)\n",
    "# https://keras.io/api/optimizers/\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 60\n",
    "batch_size = 64\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# (loss='binary_crossentropy')Specifies the loss function to be minimized during training for binary classification.\n",
    "# (metrics=['accuracy']) Tracks the accuracy metric during training to evaluate model performance.\n",
    "# Adam optimizer is an optimization algorithm used to minimize the loss function during the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0f1c8-c343-4310-8f92-7e6f43b45f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ece94-de73-47b1-aae1-8d2f0bb53879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the directories for training, validation, and testing sets\n",
    "\n",
    "train_dir = 'dataset/aug2/train'\n",
    "validation_dir = 'dataset/aug2/val'\n",
    "test_dir = 'dataset/aug2/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0fda35-3f75-45a0-a260-ca6f3c25b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the images from the specified directories into TensorFlow datasets.\n",
    "# Images are resized to 128x128 pixels, and the labels are inferred from the directory structure.\n",
    "# This function from TensorFlow's Keras API is used to load images from a directory and create an object,\n",
    "# which is an efficient and scalable way to handle data pipelines in TensorFlow.\n",
    "# for loading images is highly efficient because TensorFlow manages the loading and preprocessing in parallel, which speeds up the training process\n",
    "\n",
    "\n",
    "# https://keras.io/api/data_loading/\n",
    "# https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "# https://keras.io/examples/vision/super_resolution_sub_pixel/\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir, # Reads images from the specified directories\n",
    "    labels='inferred', # Automatically labels the images based on the directory structure (e.g., \"Normal\" as 0 and \"Pneumonia\" as 1).\n",
    "    label_mode='binary', # Specifies the type of label for the output dataset means each label will be either 0 or 1 in our case.\n",
    "    batch_size=batch_size, # The number of images to be loaded and processed in each batch.\n",
    "    image_size=(128, 128) # Resizes all images to 128x128 pixels, which is required for consistent input to the neural network\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(128, 128)\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2bfae-8293-476c-be25-54393d89f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to normalize the image pixel values to the range [0, 1] by dividing by 255.\n",
    "# It is a preprocessing step which scales the pixel values of images to a specific range, which improves the efficiency and performance of the model.\n",
    "\n",
    "# tf.cast(image, tf.float32) converts the image data type to tf.float32 (32-bit floating-point).\n",
    "# This is necessary because the pixel values are often loaded as integers (e.g., 0 to 255), \n",
    "# and floating-point precision is required for mathematical operations and model training.\n",
    "# Divides each pixel value by 255. Since pixel values range from 0 to 255, dividing by 255 scales them to the range 0,1.\n",
    "# For example, if a pixel has a value of 128, the normalization would convert it to 128/255 = 0.50196\n",
    "\n",
    "\n",
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Applying normalization to datasets\n",
    "# https://keras.io/keras_cv/\n",
    "# https://keras.io/examples/vision/image_classification_from_scratch\n",
    "\n",
    "# The .map() method applies the normalize function to all images in the dataset, ensuring that all input data is normalized before training the model.\n",
    "# (num_parallel_calls=tf.data.AUTOTUNE) tells TensorFlow to dynamically decide the number of parallel calls based on available resources.\n",
    "# This improves performance by parallelizing the data preprocessing step.\n",
    "train_dataset = train_dataset.map(normalize, num_parallel_calls=tf.data.AUTOTUNE) \n",
    "validation_dataset = validation_dataset.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# repeat() Repeating the datasets to ensure that the dataset is available for multiple epochs without interruption.\n",
    "# shuffle(): Randomizing the order of the data to prevent learning from the sequence of the data.\n",
    "# shuffle(1000): Randomly shuffles the data with a buffer size of 1000 which prevents the model from learning any patterns related to the order.\n",
    "# prefetch(): Optimizes the data pipeline by preparing the next batch of data in the background, reducing latency and improving training speed.\n",
    "\n",
    "# prefetch(buffer_size=tf.data.AUTOTUNE): Prefetches the next batch of data while the model is training on the current batch,\n",
    "# thus optimizing the input pipeline means repeat, shuffle, and prefetch operations.\n",
    "\n",
    "# By using these techniques, we are ensuring that the model has a steady flow of data, learns effectively\n",
    "# without overfitting to any order, and trains or evaluates as quickly as possible.\n",
    "\n",
    "train_dataset = train_dataset.repeat().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.repeat().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9dd683-7c5c-45b0-b4a5-528d7bc32b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "\n",
    "# Defining the checkpoint callback to save the best model (based on validation accuracy) during training to a specified file.\n",
    "\n",
    "# verbose = 1 controls the verbosity mode. When set to 1, it means it will print messages to the console every time the model is saved,\n",
    "# providing feedback during training.\n",
    "\n",
    "# save_best_only=True ensures that only the best model, based on the validation metric is saved.\n",
    "# The model is only saved if the monitored metric (val_accuracy) improves from the previous best value.\n",
    "# mode = max means the model will be saved only if the val_accuracy increases mean improves.\n",
    "checkpoint_filepath = 'best_model/withROC.keras'\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9916c-4b8e-4d09-81c3-8171b7a0382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "# https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "# https://keras.io/examples/vision/xray_classification_with_tpus/\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaee8be-cde1-4a78-8d48-5d1ff758835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test data\n",
    "# https://keras.io/examples/vision/cutmix/\n",
    "\n",
    "# The f before the quotation marks indicates that this is an f-string, a way to embed expressions inside string literals, using curly braces.\n",
    "# f means floating-point number.\n",
    "# .2 means two decimal places.\n",
    "# :.2f is a format specifier, it means it will round the number to two decimal places, resulting in 0.96.\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ea10c-89b2-44d5-9327-8d754c7421ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collects the true labels and model predictions from the test dataset for further evaluation.\n",
    "y_true = [] # A list to store the true labels from the test dataset.\n",
    "y_pred = [] # A list to store the model's predictions for the test dataset.\n",
    "\n",
    "# iterating over the test dataset to the retrieve a specific number of batches (test_steps = 15) from the test dataset.\n",
    "# It ensures that we are evaluating the model over a defined number of samples (1000 / 64 = 15)\n",
    "\n",
    "# images: The images in the current batch.\n",
    "# labels: The true labels corresponding to the images in the current batch.\n",
    "\n",
    "# labels.numpy() means converting the labels to a NumPy array\n",
    "# y_true.extend(): Appends the true labels from the current batch to the y_true list.\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    y_true.extend(labels.numpy()) \n",
    "    y_pred.extend(model.predict(images) > 0.5)  # using the trained model to generate predictions for the loaded images\n",
    "\n",
    "y_true = np.array(y_true) # Converting the y_true list to a NumPy array for easier analysis.\n",
    "y_pred = np.array(y_pred).astype(int) #Converting the y_pred list to a NumPy array and ensuring that the values are integers.\n",
    "\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)  # Calculate FPR, TPR, and thresholds\n",
    "auc_score = roc_auc_score(y_true, y_pred) # Calculate AUC\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Plotting ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5165aa-dee5-41d5-add7-ab17c874001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix and classification report\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print('Classification Report')\n",
    "target_names = ['NORMAL', 'PNEUMONIA']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "# Plot the confusion matrix and capture the axis\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax, values_format='d')\n",
    "\n",
    "# Customize title\n",
    "plt.title(\"IVGG13\", fontweight='bold', fontsize=14)\n",
    "\n",
    "# Customize axis labels\n",
    "ax.set_xlabel(\"Predicted Label\", fontsize=12)\n",
    "ax.set_ylabel(\"True Label\", fontsize=12)\n",
    "ax.tick_params(axis='both', labelsize=12) \n",
    "\n",
    "# Customize text inside the boxes\n",
    "for text in disp.text_.ravel():\n",
    "    text.set_fontsize(12)   \n",
    "    \n",
    "# Save and show\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07a67d-15bb-47eb-93a1-6b1c551a1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be1d06-66cb-4118-b1bb-30855544498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('training_validation_accuracy.png')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cae60-0496-4e39-a6be-4e64383cde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.xlim([0, 60])  # Setting x-axis range from 0 to 60\n",
    "plt.ylim([0, 3.5])   # Setting y-axis range from 0 to 5\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('training_validation_loss.png')  \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54268aa0-ce8f-4402-9809-b364b05c3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonal line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('RoC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a2f18-613f-4375-a8c0-4785edb73c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving true labels and predicted probabilities for IVGG13\n",
    "np.save('y_true_model1.npy', y_true)\n",
    "np.save('y_pred_proba_model1.npy', y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
